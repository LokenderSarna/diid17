{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1, due March 1 by midnight\n",
    "\n",
    "The goal of this problem set is to replicate and extend the results of  Jean et al.'s 2016 paper, \"Combining satellite imagery and machine learning to predict poverty.\" This problem set will be challenging and time-consuming, so I suggest you start immediately. Your first step should be to carefully read <a href=\"https://pdfs.semanticscholar.org/1b3a/c4b4187a3dbc9373869e7774b1dc63f748d2.pdf\">the original paper</a>  as well as the <a href=\"http://science.sciencemag.org/content/sci/suppl/2016/08/19/353.6301.790.DC1/Jean.SM.pdf\">supplementary materials</a>.\n",
    "\n",
    "For this assignment, we will focus on the country of Rwanda. You will need to download three distinct datasets, including DHS data, satellite data from the Google Maps API, as well as nighttime luminosity data. The DHS data requires registration (which can take several days to be approved), and the Google Maps API is rate-limited, so it will necessarily take you several days to download the requisite data, so make sure to **get started on those steps asap**. The deep learning section may also take several hours to compute (or days, if you have a slow computer), so don't save it until the last minute.\n",
    "\n",
    "## Overview of the problem set\n",
    "\n",
    "These are the key steps in the problem set:\n",
    "\n",
    "1. Download satellite night lights images from NOAA\n",
    "2. Download DHS data for Rwanda\n",
    "3. Test whether night lights data can predict wealth, as observed in DHS\n",
    "4. Download daytime satellite imagery from Google Maps\n",
    "5. Test whether basic features of daytime imagery can predict wealth\n",
    "6. Extract features from daytime imagery using deep learning libraries\n",
    "7. Replicate final model and results of Jean et al (2016)\n",
    "8. Construct maps showing the predicted distribution of wealth in Rwanda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download nightlights for Rwanda\n",
    "\n",
    "- **INPUT**:\n",
    " - None\n",
    "- **OUTPUT**: \n",
    " - `F182010.v4d_web.stable_lights.avg_vis.tif`: Single image file giving nightlights intensity around the world\n",
    "\n",
    "Go to the [DMSP-OLS website](https://ngdc.noaa.gov/eog/dmsp/downloadV4composites.html) and download the satellite nighttime luminosity data (roughly 400MB). We will use the one from 2010. The archive they provide constains several files. Feel free to explore these files. We will only be using the file F182010.v4d_web.stable_lights.avg_vis.tif.\n",
    "\n",
    "A code snippet to get you started is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "night_image_url = 'https://ngdc.noaa.gov/eog/data/web_data/v4composites/F182010.v4.tar'\n",
    "wget.download(night_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download Rwandan DHS and construct cluster-level aggregates\n",
    "\n",
    "- **INPUT**: \n",
    "  - `rwanda_clusters_location.csv`: Coordinates of the centroid of each cluster\n",
    "- **OUTPUT**: \n",
    "  - `rwanda_cluster_avg_asset_2010.csv`: Comma-delimited file indicated average wealth of each cluster \n",
    "\n",
    "[Demographic and Health Surveys (DHS)](http://dhsprogram.com/What-We-Do/Survey-Types/DHS.cfm) are nationally-representative household surveys that provide data for a wide range of monitoring and impact evaluation indicators in the areas of population, health, and nutrition. For this assignment, you will need to download the [2010 Rwandan DHS data](http://dhsprogram.com/what-we-do/survey/survey-display-364.cfm). **This requires registration, so start early!** Do not forget to request for the GPS dataset. Make sure you understand the structure of the data before starting.\n",
    "\n",
    "Your immediate goal is to take the raw survey data, covering 12,540 households, and compute the average household wealth for each survey cluster (think of a cluster as a village). Refer to the file `Recode6_DHS_22March2013_DHSG4.pdf` for information on these data.\n",
    "\n",
    "Save your output as `rwanda_cluster_avg_asset_2010.csv` and check that it matches the file that we have provided. You will use this file as input to the next step in the assignment.\n",
    "\n",
    "Hints:\n",
    "- `Household Recode` contains all the attributes of each household. It provides datasets with different formats. Feel free to explore the data. You can use `RWHR61FL.DAT` file in Flat ASCII data (.dat) format.\n",
    "- `RWHR61FL.DCF` describes the attributes and the location of each attribute.\n",
    "- Geographic Datasets: `rwge61fl.zip` contains the location of each cluster in Rwanda. It is in the format of shapefile, which needs QGIS or other GIS softwares to open. For those who are not familiar with GIS tools or who want a shortcut, you can also sue the file `rwanda_clusters_location.csv` provided with the problem set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, the cluster locations, overlaid on the nightlights data, are shown in the figure below.\n",
    "<img src=\"figure/map1.png\" alt=\"Map\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION ####\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_name = 'RWHR61FL.DAT'\n",
    "cluster_file = 'rwanda_clusters_location.csv'\n",
    "cluster_all = []\n",
    "wealth_all = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        cluster = int(line[15:23])\n",
    "        wealth = int(line[230:238]) / 100000.0\n",
    "        cluster_all.append(cluster)\n",
    "        wealth_all.append(wealth)\n",
    "\n",
    "df = pd.DataFrame({'cluster': cluster_all, 'wlthindf': wealth_all})\n",
    "cluster_avg_asset = df.groupby('cluster')['wlthindf'].median().reset_index()\n",
    "\n",
    "df_location = pd.read_csv(cluster_file)[['DHSCLUST', 'LATNUM', 'LONGNUM']]\n",
    "result = cluster_avg_asset.merge(df_location, how='inner', left_on='cluster', right_on='DHSCLUST')[['cluster', 'wlthindf', 'LATNUM', 'LONGNUM']]\n",
    "result.rename(columns={'LATNUM': 'latitude', 'LONGNUM':'longitude'}, inplace=True)\n",
    "result.to_csv('rwanda_cluster_avg_asset_2010.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test whether night lights data can predict wealth, as observed in DHS\n",
    "\n",
    "Now that you have \"ground truth\" measures of average cluster wealth, your goal is to understand whether the nightlights data can be used to predict wealth. First, merge the DHS and nightlights data, and then fit a model of wealth on nightlights.\n",
    "\n",
    "## 3.1 Merge nightlights and DHS data at cluster level\n",
    "- **INPUT**: \n",
    " - `F182010.v4d_web.stable_lights.avg_vis.tif`: Nightlights data, from Step 1\n",
    " - `rwanda_cluster_avg_asset_2010.csv`: DHS cluster averages, from Step 2\n",
    "- **OUTPUT**: Merged datasets\n",
    " - `DHS_nightlights.csv`: Merged dataset with 492 rows, and 6 columns (one indicates average cluster wealth, 5 nightlights features)\n",
    " - Scatterplot of nightlights vs. DHS wealth\n",
    "\n",
    "Perform a \"spatial join\" to compute the average nighttime luminosity for each of the DHS clusters. To do this, you should take the average of the luminosity values for the nightlights locations surrounding the cluster centroid.\n",
    "\n",
    "Save your output as `DHS_nightlights.csv` and check that it is the same as the file we have provided.\n",
    "\n",
    "Create a scatterplot showing the relationship between average cluster wealth (y-axis) and average nighttime luminosity (x-axis). Your scatterplot should have one dot for each of the 492 DHS clusters. Report the R^2 of the regression line.\n",
    "\n",
    "Hints:\n",
    " - The resolution of each pixel in the nightlight image is about 1km. Use 10 pixels X 10 pixels to average the luminosity of each cluster.\n",
    " - Start by just taking the **Mean** of the luminosity in the 100 pixels and comparing this to cluster average wealth. If you like, you could also compute other luminosity characteristics of each cluster, such as the **Max**, **Min**, **Standard Deviation** of the 100 pixel values, but this step is not required. Note that the file we provide (`DHS_nightlights.csv`) has these added features.\n",
    " - To read the raw raster (nightlights) files, we recommend using the GDAL library. Use `conda install gdal` to install the GDAL library. We have provided some helper code for this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import os.path\n",
    "from osgeo import gdal, ogr, osr\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "import cStringIO\n",
    "gdal.UseExceptions()\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "import urllib\n",
    "\n",
    "# Helper function to read a raster file\n",
    "def read_raster(raster_file):\n",
    "    \"\"\"\n",
    "    Function\n",
    "    --------\n",
    "    read_raster\n",
    "\n",
    "    Given a raster file, get the pixel size, pixel location, and pixel value\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raster_file : string\n",
    "        Path to the raster file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_size : float\n",
    "        Pixel size\n",
    "    top_left_x_coords : numpy.ndarray  shape: (number of columns,)\n",
    "        Longitude of the top-left point in each pixel\n",
    "    top_left_y_coords : numpy.ndarray  shape: (number of rows,)\n",
    "        Latitude of the top-left point in each pixel\n",
    "    centroid_x_coords : numpy.ndarray  shape: (number of columns,)\n",
    "        Longitude of the centroid in each pixel\n",
    "    centroid_y_coords : numpy.ndarray  shape: (number of rows,)\n",
    "        Latitude of the centroid in each pixel\n",
    "    bands_data : numpy.ndarray  shape: (number of rows, number of columns, 1)\n",
    "        Pixel value\n",
    "    \"\"\"\n",
    "    raster_dataset = gdal.Open(raster_file, gdal.GA_ReadOnly)\n",
    "    # get project coordination\n",
    "    proj = raster_dataset.GetProjectionRef()\n",
    "    bands_data = []\n",
    "    # Loop through all raster bands\n",
    "    for b in range(1, raster_dataset.RasterCount + 1):\n",
    "        band = raster_dataset.GetRasterBand(b)\n",
    "        bands_data.append(band.ReadAsArray())\n",
    "        no_data_value = band.GetNoDataValue()\n",
    "    bands_data = np.dstack(bands_data)\n",
    "    rows, cols, n_bands = bands_data.shape\n",
    "\n",
    "    # Get the metadata of the raster\n",
    "    geo_transform = raster_dataset.GetGeoTransform()\n",
    "    (upper_left_x, x_size, x_rotation, upper_left_y, y_rotation, y_size) = geo_transform\n",
    "    \n",
    "    # Get location of each pixel\n",
    "    x_size = 1.0 / int(round(1 / float(x_size)))\n",
    "    y_size = - x_size\n",
    "    y_index = np.arange(bands_data.shape[0])\n",
    "    x_index = np.arange(bands_data.shape[1])\n",
    "    top_left_x_coords = upper_left_x + x_index * x_size\n",
    "    top_left_y_coords = upper_left_y + y_index * y_size\n",
    "    # Add half of the cell size to get the centroid of the cell\n",
    "    centroid_x_coords = top_left_x_coords + (x_size / 2)\n",
    "    centroid_y_coords = top_left_y_coords + (y_size / 2)\n",
    "\n",
    "    return (x_size, top_left_x_coords, top_left_y_coords, centroid_x_coords, centroid_y_coords, bands_data)\n",
    "\n",
    "\n",
    "# Helper function to get the pixel index of the point\n",
    "def get_cell_idx(lon, lat, top_left_x_coords, top_left_y_coords):\n",
    "    \"\"\"\n",
    "    Function\n",
    "    --------\n",
    "    get_cell_idx\n",
    "\n",
    "    Given a point location and all the pixel locations of the raster file,\n",
    "    get the column and row index of the point in the raster\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lon : float\n",
    "        Longitude of the point\n",
    "    lat : float\n",
    "        Latitude of the point\n",
    "    top_left_x_coords : numpy.ndarray  shape: (number of columns,)\n",
    "        Longitude of the top-left point in each pixel\n",
    "    top_left_y_coords : numpy.ndarray  shape: (number of rows,)\n",
    "        Latitude of the top-left point in each pixel\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lon_idx : int\n",
    "        Column index\n",
    "    lat_idx : int\n",
    "        Row index\n",
    "    \"\"\"\n",
    "    lon_idx = np.where(top_left_x_coords < lon)[0][-1]\n",
    "    lat_idx = np.where(top_left_y_coords > lat)[0][-1]\n",
    "    return lon_idx, lat_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the nightlight image\n",
    "raster_file = 'data/nighttime_image/F182010.v4d_web.stable_lights.avg_vis.tif'\n",
    "x_size, top_left_x_coords, top_left_y_coords, centroid_x_coords, centroid_y_coords, bands_data = \\\n",
    "read_raster(raster_file)\n",
    "\n",
    "np.savez('nightlight.npz', top_left_x_coords=top_left_x_coords, top_left_y_coords=top_left_y_coords, bands_data=bands_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION ####\n",
    "\n",
    "# get nightlight features for each cluster\n",
    "def get_nightlight_feature(sample):\n",
    "    idx, wealth, x, y = sample\n",
    "    lon_idx, lat_idx = get_cell_idx(x, y, top_left_x_coords, top_left_y_coords)\n",
    "    # Select the 10 * 10 pixels\n",
    "    left_idx = lon_idx - 5\n",
    "    right_idx = lon_idx + 4\n",
    "    up_idx = lat_idx - 5\n",
    "    low_idx = lat_idx + 4\n",
    "    luminosity_100 = []\n",
    "    for i in xrange(left_idx, right_idx + 1):\n",
    "        for j in xrange(up_idx, low_idx + 1):\n",
    "            # Get the luminosity of this pixel\n",
    "            luminosity = bands_data[j, i, 0]\n",
    "            luminosity_100.append(luminosity)\n",
    "    luminosity_100 = np.asarray(luminosity_100)\n",
    "    max_ = np.max(luminosity_100)\n",
    "    min_ = np.min(luminosity_100)\n",
    "    mean_ = np.mean(luminosity_100)\n",
    "    median_ = np.median(luminosity_100)\n",
    "    std_ = np.std(luminosity_100)\n",
    "    return pd.Series({'id': idx, 'max_': max_, 'min_': min_, 'mean_': mean_, 'median_': median_, 'std_': std_, 'wealth': wealth})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = pd.read_csv('rwanda_cluster_avg_asset_2010.csv')\n",
    "data_all = clusters.apply(lambda x: get_nightlight_feature([x['cluster'], x['wlthindf'], x['longitude'], x['latitude']]), axis=1)\n",
    "data_all.to_csv('DHS_nightlights.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAF/CAYAAAC/oTuRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHQCABiChAwDQAP8fErVE9C+YzfcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114299250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(data_all['mean_'], data_all['wealth'], 'o', c='b', markersize=5, markeredgecolor='none', alpha=0.5)\n",
    "plt.xlabel('Average nighttime luminosity')\n",
    "plt.ylabel('Average cluster wealth')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Fit a model of wealth as a function of nightlights\n",
    "- **INPUT**: \n",
    " - `DHS_nightlights.csv`, from Step 3.1\n",
    "- **OUTPUT**: \n",
    " - R^2 of model\n",
    " \n",
    "Above, you fit a regression line to illustrate the relationship between cluster average wealth and corresponding cluster nightlights. Now, use [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_%28statistics%29) to get a better sense of out of sample accuracy.\n",
    "\n",
    "There are two options for this. The basic way, for those new to machine learning, is to randomly divide your dataset into a training and a test dataset. Randomly select 80% of your clusters and fit a model of cluster-average DHS wealth (your response/dependent variable) on nightlights (your predictor/independent variables). You can use a regression or any other model you prefer. Then, use that model to predict the wealth of the remaining 20% of your data, and compare the predicted values to the actual values, and report the R^2 on these 20%.\n",
    "\n",
    "The preferred way is to use 10-fold cross-validation, where you repeat the above procedure 10 times, so that you have 10 different and non-overlapping test sets. Then, you report the cross-validated R^2 of your model (i.e., the average R^2 of your 10 test folds).\n",
    "\n",
    "Hints:\n",
    " - The scikit learn library has built-in functions for [cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html) that make this quite easy.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.723991901268\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION ####\n",
    "data_all = pd.read_csv('DHS_nightlights.csv')\n",
    "data_array = data_all[['max_', 'min_', 'mean_', 'median_', 'std_', 'wealth']].as_matrix()\n",
    "np.random.seed(123)\n",
    "# np.random.shuffle(data_array)\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "scores = []\n",
    "index_all = []\n",
    "for train_index, test_index in kf.split(data_array):\n",
    "    clf = Ridge(alpha=1.0)\n",
    "    train = data_array[train_index]\n",
    "    test = data_array[test_index]\n",
    "    clf.fit(train[:, :-1], train[:, -1])\n",
    "    s = clf.score(test[:, :-1], test[:, -1])\n",
    "    scores.append(s)\n",
    "    index_all.append([train_index, test_index])\n",
    "\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908133127504\n"
     ]
    }
   ],
   "source": [
    "scores = np.asarray(scores)\n",
    "min_idx = np.where(scores == max(scores))\n",
    "\n",
    "train_index, test_index = index_all[min_idx[0][0]]\n",
    "clf = Ridge(alpha=1.0)\n",
    "train = data_array[train_index]\n",
    "test = data_array[test_index]\n",
    "clf.fit(train[:, :-1], train[:, -1])\n",
    "print clf.score(test[:, :-1], test[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "import cPickle\n",
    "with open('model_nightlight.pkl', 'wb') as fid:\n",
    "    cPickle.dump(clf, fid)    \n",
    "\n",
    "# load it again\n",
    "# with open('model_nightlight.pkl', 'rb') as fid:\n",
    "#      clf = cPickle.load(fid)\n",
    "# \n",
    "# clf.score(test[:, :-1], test[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Download daytime satellite imagery \n",
    "- **INPUT**: \n",
    " - Google Maps API key\n",
    " - `Sector_Boundary_2012.shp`: Rwandan shapefile\n",
    "- **OUTPUT**: \n",
    " - Thousands of satellite images (store in directory `google_image/`)\n",
    "\n",
    "We will use the Google Static Maps API to download satellite images. Refer [Google Static Maps introduction](https://developers.google.com/maps/documentation/static-maps/intro) and [Google Static Maps API Usage Limits](https://developers.google.com/maps/documentation/static-maps/usage-limits). You must apply for an API key before downloading. ** Note that it will take you several days to download the required images, so start early!**\n",
    "\n",
    "Download the images from Google at zoom level 16 (pixel resolution is about 2.5m). Set the image size to be 400 pixels X 400 pixels, so that each image you download will cover 1 square kilometer. In this way, each daytime image you download will correspond to a single pixel from the nighttime imagery from Step 1 above.\n",
    "\n",
    "Hints:\n",
    " - You will need to tell Google the locations for which you wish to download images. One way to do this is to use a [shapefiles](https://en.wikipedia.org/wiki/Shapefile) that specifies the borders of Rwanda. We have provided this shapefile (`Sector_Boundary_2012.shp`) as well as a helper function to read in the shapefile.\n",
    " - You can organize the files however you like. However, for later analysis (Steps 6 and beyond), it may help if you organize these daytime images into 64 folders, with one folder indicating the nightlight intensity of the pixel corresponding to the daytime image. In other words, if you download a daytime image for which the corresponding nighttime pixel has value 32, store that daytime image in a folder labeled '32'. This way, all the satellite images within each folder will have the same nightlight intensity. The file name is columnIndex_rowIndex.jpg, in which row index and column index are the index in the nightlight image (See the diagram below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](figure/data_description.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to read a shapefile\n",
    "def get_shp_extent(shp_file):\n",
    "    \"\"\"\n",
    "    Function\n",
    "    --------\n",
    "    get_shp_extent\n",
    "\n",
    "    Given a shapefile, get the extent\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shp_file : string\n",
    "        Path to the shapefile\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    extent : tuple\n",
    "        Boundary location of the shapefile (x_min, x_max, y_min, y_max)\n",
    "    \"\"\"\n",
    "    inDriver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "    inDataSource = inDriver.Open(inShapefile, 0)\n",
    "    inLayer = inDataSource.GetLayer()\n",
    "    extent = inLayer.GetExtent()\n",
    "    # x_min_shp, x_max_shp, y_min_shp, y_max_shp = extent\n",
    "    return extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapefile read\n",
      "100\n",
      "200\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "### BEGIN SOLUTION ####\n",
    "from retrying import retry\n",
    "\n",
    "\n",
    "@retry(wait_exponential_multiplier=1000, wait_exponential_max=3600000)\n",
    "def save_img(url, file_path, file_name):\n",
    "    \"\"\"\n",
    "    Function\n",
    "    --------\n",
    "    save_img\n",
    "\n",
    "    Given a url of the map, save the image\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "        URL of the map from Google Map Static API\n",
    "    file_path : string\n",
    "        Folder name of the map\n",
    "    file_name : string\n",
    "        File name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    a = urllib.urlopen(url).read()\n",
    "    b = cStringIO.StringIO(a)\n",
    "    image = ndimage.imread(b, mode='RGB')\n",
    "    # when no image exists, api will return an image with the same color. \n",
    "    # and in the center of the image, it said'Sorry. We have no imagery here'.\n",
    "    # we should drop these images if large area of the image has the same color.\n",
    "    if np.array_equal(image[:,:10,:],image[:,10:20,:]):\n",
    "        pass\n",
    "    else:\n",
    "        misc.imsave(file_path + file_name, image[50:450, :, :])\n",
    "\n",
    "# Now read in the shapefile for Rwanda and extract the edges of the country\n",
    "inShapefile = \"data/shp/Sector_Boundary_2012/Sector_Boundary_2012.shp\"\n",
    "x_min_shp, x_max_shp, y_min_shp, y_max_shp = a\n",
    "\n",
    "left_idx, top_idx = get_cell_idx(x_min_shp, y_max_shp, top_left_x_coords, top_left_y_coords)\n",
    "right_idx, bottom_idx = get_cell_idx(x_max_shp, y_min_shp, top_left_x_coords, top_left_y_coords)\n",
    "\n",
    "\n",
    "key = 'YOUR_GOOGLE_MAP_API_KEY'\n",
    "m = 1\n",
    "for i in xrange(left_idx, right_idx + 1):\n",
    "    for j in xrange(top_idx, bottom_idx + 1):\n",
    "        lon = centroid_x_coords[i]\n",
    "        lat = centroid_y_coords[j]\n",
    "        url = 'https://maps.googleapis.com/maps/api/staticmap?center=' + str(lat) + ',' + \\\n",
    "               str(lon) + '&zoom=16&size=400x500&maptype=satellite&key=' + key\n",
    "        lightness = bands_data[j, i, 0]\n",
    "        file_path = 'google_image/' + str(lightness) + '/'\n",
    "        if not os.path.isdir(file_path):\n",
    "            os.makedirs(file_path)\n",
    "        file_name = str(i) + '_' + str(j) +'.jpg'\n",
    "        save_img(url, file_path, file_name)\n",
    "        if m % 100 == 0:\n",
    "            print m\n",
    "        m += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test whether basic features of daytime imagery can predict wealth\n",
    "In step 3, you tested whether nightlight imagery could predict the wealth of Rwandan villages. You will now test whether daytime imagery can predict village wealth. Start by extracting simple metrics from the daytime imagery; in step 6 you will use more sophsticated methods to engineer these features from the images. **You don't need to do this step if you are able to do step 6.**\n",
    "\n",
    "## 5.1. Extract \"basic\" features from daytime imagery\n",
    "- **INPUT**: \n",
    " - `google_image/...`: Raw images, from Step 4\n",
    "- **OUTPUT**: \n",
    " - `google_image_features_basic.csv`: Image features \n",
    "\n",
    "Convert the raw data from the satellite imagery into a set of features that can be used in a machine learning algorithm. A simple way to do this is to take the raw R/G/B values for each pixel and average them for the image. Thus, if an image has 100 pixels, you will have an average R value, an average G value, and an average B value. Create more features by also computing the min, max, median, and standard deviation of R, G, and B for each image. This process will convert each image into a vector of 15 features.\n",
    "\n",
    "Feel free to be creative if you wish to generate additional features from the imagery -- this is similar to the process described in section 2.3 of the paper's supplementary materials. But don't waste too much time, and don't expect these features to be terribly useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION ####\n",
    "\n",
    "images_name = []\n",
    "for i in range(64):\n",
    "    dir_ = 'google_image/' + str(i) + '/'\n",
    "    image_files = os.listdir(dir_)\n",
    "    images_name.append(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_basic_feature(image_file):\n",
    "    image = ndimage.imread(image_file, mode='RGB')\n",
    "    features = []\n",
    "    for i in range(3):\n",
    "        image_one_band = image[:, :, i].flatten()\n",
    "        features.append(image_one_band)\n",
    "    return np.asarray(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_daytime_feature(sample):\n",
    "    idx, wealth, x, y = sample\n",
    "    lon_idx, lat_idx = get_cell_idx(x, y, top_left_x_coords, top_left_y_coords)\n",
    "    left_idx = lon_idx - 5\n",
    "    right_idx = lon_idx + 4\n",
    "    up_idx = lat_idx - 5\n",
    "    low_idx = lat_idx + 4\n",
    "    features_100 = []\n",
    "    for i in xrange(left_idx, right_idx + 1):\n",
    "        for j in xrange(up_idx, low_idx + 1):\n",
    "            luminosity = bands_data[j, i, 0]\n",
    "            file_name = str(i) + '_' + str(j) +'.jpg'\n",
    "            if file_name in images_name[luminosity]:\n",
    "                feature = get_image_basic_feature('google_image/' + str(luminosity) + '/' + file_name)\n",
    "                features_100.append(feature)\n",
    "    if len(features_100) == 0:\n",
    "        return np.asarray([np.nan] * 15 + [wealth]).tolist()\n",
    "    else:\n",
    "        features_all = np.concatenate(features_100, axis=1)\n",
    "        max_ = np.max(features_all, axis=1)\n",
    "        min_ = np.min(features_all, axis=1)\n",
    "        mean_ = np.mean(features_all, axis=1)\n",
    "        median_ = np.median(features_all, axis=1)\n",
    "        std_ = np.std(features_all, axis=1)\n",
    "        return np.concatenate([max_, min_, mean_, median_, std_, [wealth]]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Merge daytime images with DHS data\n",
    "\n",
    "- **INPUT**: \n",
    " - `google_image_features_basic.csv`: Satellite imagery features, from Step 5.1\n",
    " - `rwanda_cluster_avg_asset_2010.csv`: DHS cluster averages, from Step 2\n",
    "- **OUTPUT**: Merged datasets\n",
    " - `data/model/DHS_daytime.csv`: Merged dataset with 492 rows, and 16 columns (one indicates average cluster wealth, 15 daytime image features)\n",
    "\n",
    "Now that you have feature vectors for each image, you should merge these with the DHS data indicated average cluster wealth. Follow a similar procedure as you did with 3.1, i.e., determine which image feature vectors are associated with each cluster, and then calculate, for each cluster, the average value of each feature.\n",
    "\n",
    "Save your output as `DHS_daytime.csv` and check that it is roughly the same as the file we have provided. There may be slight differences if you chose to calculate a different set of features than those described in 5.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION ####\n",
    "\n",
    "clusters = pd.read_csv('rwanda_cluster_avg_asset_2010.csv')\n",
    "clusters['feature'] = clusters.apply(lambda x: get_daytime_feature([x['cluster'], x['wlthindf'], x['longitude'], x['latitude']]), axis=1)\n",
    "\n",
    "data_all = clusters['feature']\n",
    "data_all = np.asarray([i for i in data_all])\n",
    "data_all = data_all[~np.isnan(data_all).any(axis=1)]\n",
    "\n",
    "np.savetxt('google_image_features_basic.csv', data_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Fit a model of wealth as a function of basic daytime features\n",
    "- **INPUT**: \n",
    " - `data/model/DHS_daytime.csv`, from Step 5.2\n",
    "- **OUTPUT**: \n",
    " - R^2 of model\n",
    " \n",
    "As in 3.2, use 10-fold cross-validation to fit a model of cluster-level DHS wealth (your response/dependent variable) as a function of the nightlights data (your predictor/independent variables). Since you have a reasonably large number of predictor variables, you should use a model that incorporates some form of regularization (e.g., ridge regression, lasso regression, or a tree-based method).  Report the cross-validated R^2 of your model (i.e., the average R^2 of your 10 test folds).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION ####\n",
    "\n",
    "data_all = np.loadtxt('google_image_features_basic.csv')\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(data_all):\n",
    "    clf = Ridge(alpha=1.0)\n",
    "    train = data_all[train_index]\n",
    "    test = data_all[test_index]\n",
    "    clf.fit(train[:, :-1], train[:, -1])\n",
    "    s = clf.score(test[:, :-1], test[:, -1])\n",
    "    scores.append(s)\n",
    "\n",
    "print np.mean(scores) # 0.166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows_train = np.random.choice(range(len(data_all)), int(round(len(data_all) * 0.66)), replace=False)\n",
    "rows_test = list(set(range(len(data_all))) - set(rows_train))\n",
    "\n",
    "x_train = data_all[rows_train, :-1]\n",
    "x_test = data_all[rows_test, :-1]\n",
    "\n",
    "y_train = data_all[rows_train, -1]\n",
    "y_test = data_all[rows_test, -1]\n",
    "\n",
    "\n",
    "reg = RidgeCV(alphas=(0.1, 1.0, 10.0, 50.0, 100.0, 1000.0, 100000.0), cv=10)\n",
    "reg.fit(x_train, y_train)\n",
    "print reg.alpha_\n",
    "print reg.coef_\n",
    "r_square = reg.score(x_test, y_test)\n",
    "print r_square  # 0.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Extract features from daytime imagery using deep learning libraries\n",
    "\n",
    "This is where things get interesting. Above, you have seen that the RGB features of the daytime images are not great at predicting cluster average wealth (why not?). Now, you will use existing libraries to extract more meaningful features from the daytime imagery, similar to what is shown in Fig. 2 of the paper.\n",
    "\n",
    "## 6.1. Use the keras library to use a basic CNN to extract features of the daytime images \n",
    " \n",
    "- **INPUT**: \n",
    " - `google_image/...`: Raw images, from Step 4\n",
    "- **OUTPUT**: \n",
    " - `google_image_features_cnn.csv`: Image features \n",
    "\n",
    "Begin by using a Convolutional Neural Network that has been pre-trained on ImageNet to extract features from the images. We recommend using the [`Keras` library](https://keras.io/), which provides a very straightforward interface to [TensorFlow](https://www.tensorflow.org/).\n",
    "\n",
    "Hints:\n",
    " - This [short intro](https://github.com/fchollet/deep-learning-models/blob/master/README.md) will help you get started with extracting features from the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "### BEGIN SOLUTION ####\n",
    "\n",
    "from vgg16 import VGG16\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.layers.convolutional import Convolution2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Dropout\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "# load nightlight data\n",
    "npzfile = np.load('nightlight.npz')\n",
    "print npzfile.files\n",
    "top_left_x_coords = npzfile['top_left_x_coords']\n",
    "top_left_y_coords = npzfile['top_left_y_coords']\n",
    "bands_data = npzfile['bands_data']\n",
    "\n",
    "\n",
    "def get_cell_idx(lon, lat, top_left_x_coords, top_left_y_coords):\n",
    "    lon_idx = np.where(top_left_x_coords < lon)[0][-1]\n",
    "    lat_idx = np.where(top_left_y_coords > lat)[0][-1]\n",
    "    return lon_idx, lat_idx\n",
    "\n",
    "# get image featuers\n",
    "base_model = VGG16(weights='imagenet')\n",
    "model = Model(input=base_model.input, output=base_model.get_layer('fc2').output)\n",
    "\n",
    "images_name = []\n",
    "for i in range(64):\n",
    "    dir_ = 'google_image/' + str(i) + '/'\n",
    "    image_files = os.listdir(dir_)\n",
    "    images_name.append(image_files)\n",
    "\n",
    "\n",
    "def get_input_feature(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = model.predict(x)\n",
    "    return features[0]\n",
    "\n",
    "\n",
    "def get_daytime_feature(sample):\n",
    "    idx, wealth, x, y = sample\n",
    "    print idx\n",
    "    lon_idx, lat_idx = get_cell_idx(x, y, top_left_x_coords, top_left_y_coords)\n",
    "    left_idx = lon_idx - 5\n",
    "    right_idx = lon_idx + 4\n",
    "    up_idx = lat_idx - 5\n",
    "    low_idx = lat_idx + 4\n",
    "    features_100 = []\n",
    "    for i in xrange(left_idx, right_idx + 1):\n",
    "        for j in xrange(up_idx, low_idx + 1):\n",
    "            luminosity = bands_data[j, i, 0]\n",
    "            file_name = str(i) + '_' + str(j) + '.jpg'\n",
    "            if file_name in images_name[luminosity]:\n",
    "                feature = get_input_feature('google_image/' + str(luminosity) + '/' + file_name)\n",
    "                features_100.append(feature)\n",
    "    if len(features_100) == 0:\n",
    "        return np.asarray([np.nan] * 4096 + [wealth]).tolist()\n",
    "    else:\n",
    "        features_100 = np.asarray(features_100)\n",
    "        return np.append(np.mean(features_100, axis=0), wealth).tolist()\n",
    "\n",
    "\n",
    "clusters = pd.read_csv('rwanda_cluster_avg_asset_2010.csv')\n",
    "clusters['feature'] = clusters.apply(lambda x: get_daytime_feature([x['cluster'], x['wlthindf'], x['longitude'], x['latitude']]), axis=1)\n",
    "\n",
    "data_all = clusters['feature']\n",
    "data_all = np.asarray([i for i in data_all])\n",
    "data_all = data_all[~np.isnan(data_all).any(axis=1)]\n",
    "\n",
    "np.savetxt('google_image_features_cnn.csv', data_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2. Test whether these new features of satellite imagery can predict wealth\n",
    "- **INPUT**: \n",
    " - `google_image_features_cnn.csv`: Satellite imagery features, from Step 6.1\n",
    " - `rwanda_cluster_avg_asset_2010.csv`: DHS cluster averages, from Step 2\n",
    "- **OUTPUT**: Merged datasets\n",
    " - `data/model/DHS_daytime.csv`: Merged dataset with 492 rows, and 4097 columns (one indicates average cluster wealth, 4096 nightlights features)\n",
    " - R^2 of model\n",
    " \n",
    "Calculate the average value of each feature for each of the DHS clusters. As in Step 3.1 and 5.2, you will want to aggregate over images near the cluster centroid by taking the average value for each feature. Create a scatterplot showing the relationship between average cluster wealth (y-axis) and the first principal component of all of your image features (x-axis) - in other words, run PCA on your 4096 image features and plot the first PC on the x-axis. Your scatterplot should have one dot for each of the 492 DHS clusters.\n",
    "\n",
    "Use 10-fold cross-validation to fit a model of cluster-level DHS wealth (your response/dependent variable) as a function of the \"deep\" features (your predictor/independent variables). Use a model that incorporates some form of regularization (e.g., ridge regression, lasso regression, or a tree-based method).  Report the cross-validated R^2 of your model (i.e., the average R^2 of your 10 test folds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_all']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAF/CAYAAAC/oTuRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAzoREVEOMKATERHlwP8HV/dThdMVvbYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b6c38d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Your code here\n",
    "\n",
    "### BEGIN SOLUTION ####\n",
    "\n",
    "data_all = np.loadtxt('google_image_features_cnn.csv')\n",
    "x = data_all[:, :-1]\n",
    "y = data_all[:, -1]\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(x)\n",
    "proj = pca.fit_transform(x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(proj[:,0], y, 'o', c='blue', markersize=5, markeredgecolor='none', alpha=0.5)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('Average wealth index')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.632258913315\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(data_all):\n",
    "    clf = Ridge(alpha=100.0)\n",
    "    train = data_all[train_index]\n",
    "    test = data_all[test_index]\n",
    "    clf.fit(train[:, :-1], train[:, -1])\n",
    "    s = clf.score(test[:, :-1], test[:, -1])\n",
    "    scores.append(s)\n",
    "\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "[-0.00136089  0.00933641 -0.00490216 ..., -0.00042343 -0.00541549\n",
      " -0.00153458]\n",
      "0.602143580254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "rows_train = np.random.choice(range(len(data_all)), int(round(len(data_all) * 0.66)), replace=False)\n",
    "rows_test = list(set(range(len(data_all))) - set(rows_train))\n",
    "\n",
    "x_train = data_all[rows_train, :-1]\n",
    "x_test = data_all[rows_test, :-1]\n",
    "\n",
    "y_train = data_all[rows_train, -1]\n",
    "y_test = data_all[rows_test, -1]\n",
    "\n",
    "\n",
    "# ridge\n",
    "reg = RidgeCV(alphas=(0.1, 1.0, 10.0, 50.0, 100.0, 1000.0, 100000.0), cv=10)\n",
    "reg.fit(x_train, y_train)\n",
    "print reg.alpha_\n",
    "print reg.coef_\n",
    "r_square = reg.score(x_test, y_test)\n",
    "print r_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Replicate final model and results of Jean et al (2016)\n",
    "\n",
    "The only thing missing at this point is the \"transfer learning\" step. In other words, instead of using the image features extracted by the CNN directly, we want to retrain the CNN to predict nightlights from daytime imagery, and use those features, which presumably are more appropriate to our final prediction task.\n",
    "\n",
    "## 7.1. Use the nightlights to retrain the CNN and extract features\n",
    "\n",
    "Following the approach used in the paper, first divide your daytime images into three groups, corresponding to images where the corresponding night-lights pixel is dim, medium, or bright. Use these values to define your groups: [0, 3), [3, 35), [35, 64). We have given you the code to do this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def move_to_group(lightness_small, lightness_big, class_id):\n",
    "    new_directory = 'google_image_cnn/class_' + str(class_id) + '/'\n",
    "    if not os.path.isdir(new_directory):\n",
    "        os.makedirs(new_directory)\n",
    "    for i in range(lightness_small, lightness_big):\n",
    "        path = 'google_image/' + str(i) + '/'\n",
    "        for f in os.listdir(path):\n",
    "            copyfile(path + f, new_directory + f)\n",
    "\n",
    "move_to_group(0, 3, 1)\n",
    "move_to_group(3, 35, 2)\n",
    "move_to_group(35, 64, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Test whether \"deep\" features of satellite imagery can predict wealth\n",
    "- **INPUT**: \n",
    " - `google_image_cnn/...`: Satellite images from 7.1\n",
    "- **OUTPUT**: \n",
    " - `Model`: store as object xxx\n",
    " \n",
    "**TODO: add description of what needs to be done**\n",
    "\n",
    "Hints:\n",
    " - X \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "model_old = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "def get_input_feature(img_path):\n",
    "    # img = image.load_img(img_path, target_size=(400, 400))\n",
    "    img = image.load_img(img_path)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = model_old.predict(x)\n",
    "    return features[0]\n",
    "\n",
    "\n",
    "all_figures = []\n",
    "trainLabels = []\n",
    "\n",
    "path_1 = 'google_image_cnn_upsampling/class_1/'\n",
    "class_1_files = os.listdir(path_1)\n",
    "trainLabels += [[1, 0, 0]] * len(class_1_files)\n",
    "all_figures += [path_1 + i for i in class_1_files]\n",
    "\n",
    "path_2 = 'google_image_cnn_upsampling/class_2/'\n",
    "class_2_files = os.listdir(path_2)\n",
    "trainLabels += [[0, 1, 0]] * len(class_2_files)\n",
    "all_figures += [path_2 + i for i in class_2_files]\n",
    "\n",
    "path_3 = 'google_image_cnn_upsampling/class_3/'\n",
    "class_3_files = os.listdir(path_3)\n",
    "trainLabels += [[0, 0, 1]] * len(class_3_files)\n",
    "all_figures += [path_3 + i for i in class_3_files]\n",
    "\n",
    "\n",
    "# a = get_input_feature(all_figures[0])\n",
    "# pool = Pool(10)\n",
    "# trainData = pool.map(get_input_feature, all_figures)\n",
    "\n",
    "trainData = []\n",
    "t1 = time.time()\n",
    "for idx, i in enumerate(all_figures):\n",
    "    a = get_input_feature(i)\n",
    "    trainData.append(a)\n",
    "    if idx % 1000 == 0:\n",
    "        t2 = time.time()\n",
    "        print idx\n",
    "        print t2 - t1\n",
    "        t1 = time.time()\n",
    "\n",
    "\n",
    "x_all = np.asarray(trainData)\n",
    "y_all = np.asarray(trainLabels)\n",
    "\n",
    "# np.savez('google_image_feature.npz', x_all=x_all, y_all=y_all)\n",
    "np.savez('google_image_feature_not_upsampling.npz', x_all=x_all, y_all=y_all)\n",
    "\n",
    "npzfile = np.load('google_image_feature.npz')\n",
    "print npzfile.files\n",
    "x_all = npzfile['x_all']\n",
    "y_all = npzfile['y_all']\n",
    "\n",
    "\n",
    "np.random.seed(seed=123)\n",
    "\n",
    "class_1_num = y_all[:,0].sum()\n",
    "class_2_num = y_all[:,1].sum()\n",
    "class_3_num = y_all[:,2].sum()\n",
    "\n",
    "x_all_1 = x_all[:class_1_num, ]\n",
    "x_all_2 = x_all[class_1_num:(class_1_num + class_2_num), ]\n",
    "x_all_3 = x_all[(class_1_num + class_2_num):, ]\n",
    "\n",
    "y_all_1 = y_all[:class_1_num, ]\n",
    "y_all_2 = y_all[class_1_num:(class_1_num + class_2_num), ]\n",
    "y_all_3 = y_all[(class_1_num + class_2_num):, ]\n",
    "\n",
    "\n",
    "# for each class, select 33% as the test set\n",
    "rows_train = np.random.choice(range(len(x_all)), int(round(len(x_all) * 0.66)), replace=False)\n",
    "rows_test = list(set(range(len(x_all))) - set(rows_train))\n",
    "\n",
    "x_train = x_all[rows_train]\n",
    "x_test = x_all[rows_test]\n",
    "y_train = y_all[rows_train]\n",
    "y_test = y_all[rows_test]\n",
    "\n",
    "\n",
    "# the model configuration: https://github.com/nealjean/predicting-poverty/blob/master/model/predicting_poverty_deploy.prototxt\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(4096, 6, 6, activation='relu', input_shape=(12, 12, 512), subsample=(6, 6), name='input'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, 1, 1, activation='relu', subsample=(1, 1), name='conv_7'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, 1, 1, subsample=(1, 1), name='conv_8'))\n",
    "model.add(AveragePooling2D((2, 2), strides=(1, 1), name='add_pool'))\n",
    "\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "opt = SGD(lr=1e-2)\n",
    "# model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=100, nb_epoch=2000, verbose=1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have an understanding how convolution layers work, can you visulize the weights in one convolution layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Construct map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INPUT**: Model, image features (data/model/features_all_predictimage_location.csv)\n",
    "\n",
    "**OUTPUT**: Map ('poverty_mapping.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def array_to_raster(x_size, y_size, left, top, bands_data, no_data_value, filename):\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "\n",
    "    dataset = driver.Create(\n",
    "        filename,\n",
    "        bands_data.shape[1],\n",
    "        bands_data.shape[0],\n",
    "        1,\n",
    "        gdal.GDT_Float32, )\n",
    "\n",
    "    dataset.SetGeoTransform((\n",
    "        left,\n",
    "        x_size,\n",
    "        0,\n",
    "        top,\n",
    "        0,\n",
    "        y_size))\n",
    "\n",
    "    # dataset.SetProjection(wgs84)\n",
    "    outband = dataset.GetRasterBand(1)\n",
    "    outband.WriteArray(bands_data[:, :, 0])\n",
    "    outband.FlushCache()  # Write to disk.\n",
    "    outband.SetNoDataValue(no_data_value)\n",
    "\n",
    "\n",
    "features_all_predict = np.genfromtxt('data/model/features_all_predict.csv', delimiter=',')\n",
    "image_loc = np.genfromtxt('data/model/image_loc.csv', delimiter=',')\n",
    "\n",
    "x_image_num = right_idx + 1 - left_idx\n",
    "y_image_num = bottom_idx + 1 - top_idx\n",
    "\n",
    "output_array = np.ndarray(shape=(y_image_num, x_image_num, 1))\n",
    "no_data_value = 100\n",
    "output_array.fill(no_data_value)\n",
    "\n",
    "for idx, v in enumerate(image_loc):\n",
    "    x, y = v\n",
    "    x_id = x - left_idx\n",
    "    y_id = y - top_idx\n",
    "    output_array[y_id, x_id, 0] = features_all_predict[idx]\n",
    "\n",
    "array_to_raster(x_size, - x_size, top_left_x_coords[left_idx], top_left_y_coords[top_idx], output_array, no_data_value, 'poverty_mapping.tiff')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
